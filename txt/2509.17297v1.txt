[preprint,review,12pt]elsarticle

[fleqn]amsmath

[subfigure]labelformat=simple, labelsep=period 
) 

[label font=bf,labelformat=simple]subfig
[font=small,skip=0pt]caption
[table]capposition=top
[figure]style=plain,subcapbesideposition=top

[version=4]mhchem
[symbol]footmisc

[dvipsnames]xcolor

Fig.

[1]Hanying~Yang

[1,2]James~C.~Massey
[1]Nedunchezhian~Swaminathan

[1]Department~of~Engineering, University~of~Cambridge, Trumpington~Street, Cambridge~CB2~1PZ,~United~Kingdom
[2]Robinson~College, University~of~Cambridge, Grange~Road, Cambridge~CB3~9AN,~United~Kingdom

Machine learning (ML) models are often constrained by their limitations in extrapolation, which restricts their applicability in engineering contexts. Conversely, while exhibiting broad generality, many established scientific models seem to lack the necessary accuracy. This study addresses these challenges by introducing JPResUnet (Joint PDF Residual U-net), a novel model that integrates the strengths of both ML and traditional scientific approaches to predict sub-grid joint probability density functions (PDFs) in partially premixed flames. JPResUnet employs a residual U-Net architecture to translate classic $$-PDFs to sub-grid PDFs. The model is trained using direct numerical simulation (DNS) data from methane--air moderate or intense low-oxygen dilution (MILD) combustion and is initially tested through a priori assessments on out-of-sample data. Comparative analyses against an artificial neural network (ANN) and the $$-PDF approach demonstrate that JPResUnet consistently outperforms these methods in capturing complex sub-grid features with greater accuracy and robustness for both box and Gaussian kernels of varying widths. Further evaluations on a different case reveal the modelâ€™s generalisability, where the ANN is unable to produce satisfactory prediction. Subsequent a posteriori assessment involves two versions of JPResUnet with different output PDF resolutions, which are deployed for large eddy simulation (LES) of a multi-regime burner through the look-up table (LUT) approach. The higher resolution model yields improvements in temperature estimates compared to the conventional LUT method. This highlights the potential of the JPResUnet model for robust and accurate LES of reacting flows with ML.

Joint probability density function Partially premixed flame Residual U-net MILD combustion Multi-regime combustion

Introduction
 
Large eddy simulation (LES) has emerged as an important tool for the simulation of large-scale combustion systems, particularly in scenarios where fully resolving flow fields is computationally prohibitive. By employing a spatial filter, LES effectively resolves physical processes associated with scales larger than the filter width $$, while smaller scales, collectively referred to as the sub-grid scale (SGS) range, are modelled. Over the past half-century, turbulent convection and diffusion within the SGS range have been extensively studied, leading to the development of accurate models for both non-reacting and reacting flows . However, modelling sub-grid reactions presents significant challenges due to the highly nonlinear nature of chemical processes and their complex interactions with turbulence . Although presumed probability density functions (PDFs) have been widely utilised to capture sub-grid fluctuations in thermo-chemical quantities for premixed , non-premixed , and partially premixed flames, this approach can encounter limitations under specific conditions, such as combustion with multiple fuel streams of varying composition, multi-regime combustion, and multi-phase flows. In the context of partially premixed flames, additional difficulties arise due to the strong correlation between the progress variable and the mixture fraction, whereas the presumed joint PDF approach typically assumes statistical independence between these two scalars at the sub-grid level . 

The use of machine learning (ML) as an alternative to traditional reaction rate modelling has been explored for over 30 years, with early studies focusing on the development of artificial neural networks (ANNs) to model chemical kinetics . Ihme et al. later proposed a systematic approach to optimise these techniques. The advent of deep learning has led to the exploration of more complex ANN structures for sub-grid PDF modelling. De Frahan et al. T.HenrydeFrahan2019 validated the predictive capabilities of ANNs for the marginal PDF of the progress variable in swirling methane--air premixed flames. Similarly, Yao et al. demonstrated that ANNs could predict the marginal PDF of the mixture fraction in turbulent spray flames more accurately than conventional presumed PDFs. Chen et al. further extended this approach to predict the joint PDF of the progress variable and mixture fraction in a partially premixed flame, specifically in moderate or intense low-oxygen dilution (MILD) combustion. Despite these advancements, most studies are self-testing, meaning that the training and testing data share similar thermo-chemical and -physical conditions. To assess the generalisability of ANNs, Yang et al. tested a model trained on MILD combustion data across five different premixed flames. The ANN performed well when applied to flames with the same fuel as in the MILD cases. However, its predictive accuracy diminished when there were deviations from the training conditions, such as increased filter size or a shift to hydrogen--air flames, underscoring the challenges for developing ML models with broad generalisability.

The rapid advancements in deep learning have led to the emergence of novel ML architectures with exceptional predictive capabilities, particularly in domains such as computer vision and natural language processing . These advances have also been leveraged in many fields, including biology and material science . In the context of combustion, Xing et al. employed a deep convolutional neural network (CNN) with a U-net architecture, commonly used in image processing , to predict the progress variable SGS variance. Trained on a planar flame in homogeneous isotropic turbulence and tested on a complex slot jet flame, the model demonstrated good agreement with direct numerical simulation (DNS), thus verifying its generalisability. Nista et al. utilised a generative adversarial network (GAN), originally designed for computer vision , to recover fully resolved flow fields from LES input. This GAN outperformed other models across various thermo-chemical and -physical test conditions.

Inspired by the image translation techniques in computer vision, this study aims to develop and test a U-net-based model, referred to as JPResUnet (Joint PDF Residual U-net), to infer joint sub-grid PDFs based on presumed distributions while maintaining generalisability. The model is trained on data from a single MILD combustion case and tested on unseen samples from different cases with varying filter sizes and types. Additionally, a posteriori assessment through LES for a multi-regime burner (MRB) is conducted to evaluate the model's practical performance. 

The structure of the paper is as follows. Section provides a theoretical overview of turbulent combustion modelling in LES and the concept of PDF translation. Section details the methodology for training the JPResUnet model and describes the training dataset. Section compares the joint PDFs predicted by the JPResUnet and corresponding values from DNS, alongside a discussion of the filtered reaction rate modelled via these PDFs. Results from a posteriori assessment are discussed in Section , and conclusions are summarised in the final section.

Theoretical background
 

Governing equations
 
In terms of the LES implemented by present work, the mass, momentum and total enthalpy are transported as 

 t + () = 0,
 

 t = -+ [- ( - ) ],
 

 t = [- (h - ) ].
 

The symbols $$, $$ and $h$ represent density, velocity vector and thermo-chemical enthalpy (sum of sensible and chemical enthalpies) respectively. Filtering and Favre-filtering operations are denoted by $$ and $$, respectively. The operator $/t=/ t + $ is the material derivative. The shear stress $$ in Eq. () is calculated as $=2[ - 1/3( )]$, where $$ is the molecular dynamic viscosity, $$ is the strain rate tensor defined as $0.5[+()^]$, and $$ is the identity matrix. The term within the parentheses in Eq. () represents the residual stress tensor $^R$. It is unclosed and modelled as $^R=2(_)/3-2_T[ - ( )/3]$, where $_$ is the turbulent kinetic energy at the sub-grid scale and $_T$ is the turbulent viscosity. The latter is modelled using the $-$model as $_T=(C_)^2_$ , where the model constant $C_=1.5$ is decided similar to . The operator $_$ denotes the differential operator related to the singular values of the Jacobian matrix of the velocity. The molecular thermal diffusivity $$ in Eq. () is calculated as $=/$, where $$ is the molecular kinematic viscosity, and $=0.7$ is the Prandtl number. The sub-grid scalar flux in Eq. () is modelled as $h-=-(_T/_T)$, where $_T=0.7$ is the turbulent Prandtl number following the previous study on the MRB considered in the a posteriori assessment .

Combustion closure
 
A joint PDF-based tabulation method is used for combustion modelling. During the simulation, unclosed thermo-chemical scalars are retrieved from a four-dimensional look-up table (LUT) parameterised by the filtered progress variable $$, the mixture fraction $$ and their respective sub-grid variance $_c,^2$ and $_Z,^2$. The progress variable $c$ is defined as $(Y_+Y__2)/(Y_+Y__2)^$, where the superscript `eq' denotes the equilibrium state for a given mixture fraction following previous studies that used methane--air mixtures . The mixture fraction $Z$ is defined according to Bilger . These quantities are transported using 

 t (+_T ) + ^*,
 

 t (+_T ),
 

 &_c,^2t (+_T )_c,^2 - 2_c,\\ 
 &+ 2_T( ) + 2(^*-^*),
 

 &_Z,^2t (+_T )_Z,^2 - 2_Z,\\ 
 &+ 2_T( ),
 

where the turbulent Schmidt number $_T$ is assigned as a constant value of 0.4 following the previous study on the MRB considered in the a posteriori assessment . The term $$ is calculated as $ / $ with the molecular Schmidt number $=0.7$ . The sub-grid scalar dissipation rate (SDR) for the progress variable and mixture fraction are denoted respectively as $_c,$ and $_Z,$. $_c,$ is modelled using a model proposed by Dunstan et al. , which has been validated by many studies . $_Z,$ is modelled using a linear relaxation model as $_Z,=C_Z(_T/^2)_Z,^2$ with a constant $C_Z=2$ . 

The source term $^*$ in Eq. () and () originates from three components : premixed combustion $_$, non-premixed combustion $_$, and their interaction through the cross dissipation rate $_$. This cross dissipation term is neglected following previous studies . The premixed combustion term is modelled as

_= _0^1 _0^1 (,)(,)(,) \, \,,

where $$ and $$ are the sample space variables for $c$ and $Z$ respectively. The flamelet reaction rate $$ and density $$ are obtained by solving one-dimensional unstrained planar laminar premixed flames over the flammability of the methane--air flame using the GRI-Mech 3.0 chemical mechanism in Cantera . The non-premixed combustion mode is modelled by using the marginal PDF of the mixture fraction as 

_=_Z _0^1 ^()()d ^2() \,,

where $_Z=( )+_Z,$, as seen in the work and $=Y_+Y__2$. Another source term in Eq. () is assumed as $^* _$ , and it is modelled similar to Eq. (). 

Presumed joint PDF
 
Typically, the joint PDF in Eq. () is calculated as the product of two marginal PDFs of progress variable and mixture fraction , based on the assumption of the statistical independence between these two scalars at sub-grid level. Hence, 

(,)=_(;,_c,^2) _(;,_Z,^2),

where the marginal PDF is presumed with the $$-PDF distribution. This presumed distribution is calculated as

 (;,_c,^2) = (a)(b)^a-1(1-)^b-1,
 

where $a=(1/_c-1)$, $b=(1-)(1/_c-1)$ and $$ is the $gamma$ function. $_c$ is the segregation factor, calculated as $_c=_c,^2/((1-))$. The marginal PDF for the mixture fraction is calculated in a similar way. 

The statistical independence in Eq. () may not hold in partially premixed flames due to the evident correlation between the progress variable and mixture fraction at the SGS level when the grid width is large. Alternative models, such as the copula , which accounts for the cross-correlation, have been suggested but require additional transport equations for sub-grid covariance between $c$ and $Z$, leading to increased complexity and need for further modelling. Consequently, the present work utilises the presumed joint PDF formulation (Eq. ()) and considers incorporating copula models in future studies. 

PDF-to-PDF translation model
 

To improve the accuracy of PDF predictions, this study develops the JPResUnet model, a PDF-to-PDF translation framework inspired by supervised image-to-image translation techniques. This model translates from a source probability space $\,,\_A$ to the target probability space $\,,\_B$, where $$ is the sample space, $$ denotes the $$--algebra on $$, and $$ is the probability measure. Regarding the partially premixed flame, the sample space $$ is 2-dimensional, constituted by the progress variable $c [0,1]$ and mixture fraction $Z [0,1]$. The model is designed for self-translation, implying that the source and target probability spaces originate from the same flame field, with identical $-$algebras, i.e., $_A=_B=$. Therefore, the translation is constrained to the probability measure $$, which is described through the PDF $P$ for the continuous random variables. This process is displayed as,

 P_AB(,) = _^A B(P_A(,)) (,) ,

where the subscript $$ denotes the parameter of the model $$, and the outcome of the model, $P_AB$, is associated with the probability space $B$. 

The model is optimised by minimising the loss function $$ as 

 _ &= _ _, [ P_AB(,)-P_B(,)_2 ] \\
 &=_ _, [ _(P_A(,))-P_B(,)_2 ],

which is calculated by using the L2 norm, to ensure that the translated PDF $P_AB$ is indistinguishable from the target PDF $P_B$. The trained model is expected to be applied to cases, where the distance between $P_A$ and $P_B$ in PDF space is not much larger than the training case. Given that the input $P_A$ is based on the presumed joint PDF which is generally consistent with the target sub-grid distribution $P_B$, the scope of application is supposed to cover most combustion cases, thus the model's generalisability is enhanced. For this study, the joint PDF is calculated using the $$-PDF distributions in Eq. ().

In summary, JPResUnet is trained using pairs of joint PDFs derived from the $$-distribution and DNS as input and target, respectively, following the optimisation framework given in Eq. (). A detailed discussion of data extraction and model structure follows in the subsequent sections.

Data preprocessing and numerical setup
 

DNS cases
 
The JPResUnet is trained by using the DNS dataset of MILD combustion with varying mixture fractions and internal recirculation of exhaust gases (EGR). This combustion features a partially premixed combustion mode, indicated by the flame index observed across a wide field of the computational domain . In addition, a broad reaction zone is noted in MILD combustion , which implies significant subgrid-scale fluctuations in the thermo-chemical and -physical properties of the reacting mixture. These fluctuations are advantageous for training purposes, as they contribute to the development of a robust and generalised model.

The study focuses on two MILD combustion cases with different levels of dilution, labelled `AZ1' and `BZ1'. The initial thermo-chemical and -physical conditions for these cases are detailed in Table . For both cases, the initial root-mean-square (RMS) value of the velocity fluctuation $u'_$ is around m/s and the integral length scale of the turbulence $_0$ is around mm. Based on these quantities, the turbulent Reynolds number $_T$ and the Taylor micro-scale Reynolds number $_$ are 96 and 34.73, respectively. The ratio between the integral length scales of the progress variable and mixture fraction fields is $l_c/l_Z 0.77$. The averaged progress variable is $ c =0.56$, and the RMS value of the initial fluctuation in the progress variable field is $_c/ c = 0.46$. Compared with the case AZ1, the dilution is enhanced for the case BZ1, where the oxygen level is reduced to $2\

The combustion behaviour varies significantly with different dilution levels. In AZ1, both thin and thick heat release zones, with a large variation in typical thickness, are observed, where the thickened zone is induced by the interaction of reaction zones. In contrast, BZ1 exhibits a much thicker heat release zone nearly over the whole computational domain, indicating more frequent interactions of reaction zones . To capture a wide range of combustion phenomena, training data is collected from the AZ1 case, while the BZ1 case is used for testing, as outlined in Table .

A cubic computational domain of dimensions $L_x L_y L_z = 10 10 $ mm^3 was used, with 512 grid points in each spatial direction . The resulting grid size is $ x $ m, providing approximately 30 grid points within the smallest chemical thickness of methane--air combustion. Combustion chemistry is modelled using a modified chemical mechanism, MS-58, which is based on the Smooke and Giovangigli scheme and has been enhanced to include $^*$ chemistry . The MILD combustion was simulated using a DNS code, SENGA , with a timestep of $ t = ns$. After the first flow-through time, $_f = L_x / U_$, where $U_ = m/s$ representing the inflow bulk mean velocity, the initial transient exited the computational domain, and the simulation continued for another half of $_f$ for data collection (approximately 60 snapshots). Further details regarding the numerical schemes, chemical mechanism, boundary conditions, and initial conditions can be found in .

PDF extraction
 
The PDFs are extracted from the sub-filter space within the DNS fields. For this study, the input PDFs are computed using a $$-PDF in Eq. (), for given Favre filtered quantities, $$, $_c,^2$, $$ and $_Z,^2$. The progress variable is defined using temperature, $c=(T-T_u)/(T_b(Z)-T_u)$, where $T_u=K$ is the initial temperature for the unburnt mixture. The burnt mixture temperature, $T_b$, is calculated by using the local mixture fraction . Since combustion is adiabatic, this progress variable is equal to the one defined using species (with unity Lewis number) mass fractions, described previously and used for a posteriori assessment. Hereinafter, the temperature-based progress variable is represented by $c_T$ to avoid ambiguity. 

The progress variable-related quantities are calculated as

 (x,t) = (x,t)_x-2^x+2 (x',t) c_T(x',t) (x') \,dx' \, ,

 &_c_T,^2(x,t) = \\
 &(x,t)_x-2^x+2 (x',t) [c_T(x',t)-(x,t) ]^2 (x') \,dx' \, ,

where the prime $x'$ represents local position inside the filter of size $$, and $$ is the filter kernel. The Favre filtered mixture fraction and its variance are calculated using similar procedures on the DNS data. Two types of filter kernels are used: a spatial box filter and a Gaussian filter, and they are expressed as

 &_(x') = 
 
 & \; |x'-x| 2 \\
 0 & 
 \\
&_(x') = (^2)^2(-^2).
 

As noted in Table , the normalised box filter kernel width of $^+=/_^=1$ is employed for training. The term $_^$ is the reference thermal thickness of stoichiometric laminar flame with the size of mm ($80 x$) and mm ($148 x$) for AZ1 and BZ1, respectively. Different filter sizes and Gaussian kernels are used during the testing phase.

The target joint distribution, denoted as $(,;x,t)$, is calculated by using the kernel density estimation (KDE) as

(,;x,t)=nh_i=1^nK[(x,t)( c_T, Z_)_ih ],

where $K$ and $h$ denote the kernel function and bandwidth, respectively. In this study, a bandwidth of 0.1 is used, and the Epanechnikov kernel is chosen for its computational efficiency, as it requires fewer samples $n$ only. This kernel is defined as

 K(s)=
 
 4(1-s^2) & \; |s| 1 \\
 0 & .
 

The sample space variables $$ and $$ in Eq. () are for the density-weighted progress variable and scaled mixture fraction, respectively. The scaled mixture fraction is expressed as $=(/Z_)$ , which generates a relatively uniform distribution for flames with different flammability limits and stoichiometric values of the mixture fraction. The random variable space is discretised into a grid with dimensions $N_ N_=80 100$. The progress variable dimension is linearly discretised, while the scaled mixture fraction dimension is split into two segments, $[-1.5, 0.3]$ and $[0.3, 1.8]$, with 65 and 33 points allocated respectively following earlier study . The prediction is transferred back to the $$--$$ space as $(,;x,t)=(,;x,t)/$ . For notational simplicity and clarity, $c_T$ and $Z$ are used directly instead of the sample-space variables for the PDFs, e.g., $(c_T,Z)$, $(c_T)$, $(Z)$, hereafter in this work.

It is noted that the joint distribution $(c_T,Z)$ obtained above is the filter density function (FDF) . The FDF is constructed from sub-filter space samples at a specific spatial location in a single DNS snapshot. Since DNS realisations are inherently unsteady, the FDF includes random variations , differing from the expected sub-grid PDF $(c_T,Z)$. To minimise this randomness, more samples from the sub-filter space would be required across multiple realisations with identical resolved fields , which is computationally expensive. Alternatively, this randomness can be significantly reduced if the training dataset for machine learning incorporates FDF samples collected over many realisations during a statistically stationary state . For this study, 25 DNS snapshots of the AZ1 MILD combustion case are selected. In each snapshot, the sub-filter space is systematically marched with a fixed spatial step to extract pairs of input-target PDFs. This process yields a training dataset of 33,275 samples, with $20\

Machine learning algorithm
 

The JPResUnet model features an encoder-decoder structure with skip connections, and each level within this structure utilises residual blocks, as shown in Fig. a. Its architecture can be summarised as follows:

 A cross-embedding layer and a residual block with an additional convolutional layer are deployed at the encoder-decoder's inlet and outlet, respectively. 
 The encoder and decoder are organised into three levels, each comprising three consecutive residual blocks followed by a size-changing unit. 
 Levels are connected via skip connections that integrate the input at each encoder level into the corresponding decoder level.
 Two residual blocks are positioned at the bottleneck of the model.

The cross-embedding layer (highlighted in blue in Fig. a) adjusts the input to match the number of channels required by the encoder. This is achieved through three groups of convolutional kernels with sizes of $3 3$, $7 7$, and $15 15$. The output from each kernel is padded to maintain the same size, and these outputs are concatenated along the channel dimension to reach the desired number of channels $N_$. The kernel allocation is divided into $N_/2$, $N_/4$ and $N_/4$ for the respective groups.

The residual blocks address the degradation issues often encountered in deep models by adding the input upstream to the residual function's output . This function includes a combination of group normalisation , a Sigmoid-Weighted Linear Unit (SiLU) , and a $33$ convolution, which is repeated once, as illustrated in Fig. b. The SiLU activation function, which outperforms the commonly used rectified linear unit (ReLU) in deep models by preventing inactive neurons during training, is defined as

 (x) = x * S(x),
 

where $S(x) = 1/(1+e^x)$ is the sigmoid function.

The size-changing unit, highlighted in green in Fig. a, adjusts the input size to the required value. For an input with the shape $(N_^i,N_c_T,N_Z)$, the down-sampling unit changes it to $(N_^i+1,N_c_T/2,N_Z/2)$ by using a $44$ convolutional layer, where the superscript $i$ represents the model's level. The up-sampling unit, combining interpolation with a $33$ convolution, restores the output to $(N_^i+1,2N_c_T,2N_Z)$. A parallel unit uses two groups of convolutions with kernel sizes of $33$ and $11$ respectively, both producing outputs of shape $(N_^i+1,N_c_T,N_Z)$, which are then summed. 

To preserve spatial information and facilitate gradient flow, skip connections are employed between the corresponding levels of the encoder and decoder. They scale the input at the $i^$ level of the encoder by $2^-1/2$ and concatenate it with the input at the corresponding decoder level along the channel dimension, resulting in a new input shape of $(N_^i,+N_^i,,N_c_T,N_Z)$, where `ec' and `dc' denote the encoder and decoder respectively.

The JPResUnet's input PDF is a single-channel image sized at $80100$. The cross-embedding layer expands this into a shape of $(32,80,100)$. The encoder reduces the image resolution to $(128,20,25)$, and the decoder, which mirrors the encoder's structure, restores the resolution to $(32,80,100)$. The final residual block and convolution ensure the output PDF has the same size as the input. The detailed input-output information for every component of the JPResUnet is listed in . It is noted that many iterations of the model's architecture have been tested, including the number of channels of the image generated by the cross-embedding layer, the number of levels in the encoder and decoder, and the number of residual blocks at each level. The current layout of the model shows the best performance and is adopted by the present study. 

The JPResUnet is implemented using PyTorch . Optimisation in Eq. () is handled by the AdamW algorithm , with a weight decay of $0.01$, an initial learning rate of $10^-4$, and a linear decay to $10^-7$ in 200 epochs. The batch size is set to 32. These hyperparameters were fine-tuned using the grid-search method. Training was halted at around 121 epochs as no further drop in validation loss was observed, taking about 6 hours on an NVIDIA GeForce RTX 4090 GPU.

Performance of JPResUnet on different testing cases
 

The generality and effectiveness of the JPResUnet model were evaluated through a comparative study across different cases with varying levels of extrapolation, as outlined in Table . To demonstrate the performance of JPResUnet, it was compared with an artificial neural network (ANN) consisting of three fully connected layers, with 256 and 512 neurons in the two hidden layers, respectively. This ANN was based on a previous work that successfully predicted the sub-grid PDF for MILD combustion. The ANN was modified for extrapolation using a methodology described in . The input features for the ANN included the Favre-filtered quantities $$, $_c$, $$ and $_Z$, while the output was the joint PDF $(c_T,)$. Both the JPResUnet and ANN models were trained on the same dataset as described in Section of the study.

Validation: in-sample prediction

The extrapolation capability of JPResUnet was tested on data that is slightly different from the training dataset. Within the temporal domain spanned by snapshots of the AZ1 flame used for training, three additional realisations of the flame were selected for in-sample predictions. 

The JPResUnet model's ability to predict the joint PDF for a sub-grid space within the reaction region of AZ1 was compared with that of the ANN and the analytical model $$-PDF. The results, presented in Fig. of the study, include the marginal PDFs $(c_T)=(c_T,Z)Z$ and $(Z)=(c_T,Z)c_T$. JPResUnet captures the bi-modal distribution of the progress variable and a negative correlation between $c_T$ and $Z$, characteristic of MILD combustion under the AZ1 conditions , with contours closely matching DNS data. The ANN's prediction shows a similar agreement with the DNS, which is expected as many studies have verified such excellent in-sample prediction . In contrast, the analytic model, $$-PDF, fails to capture the DNS data's shape and peak.

 

The overall accuracy of the JPResUnet model across the entire testing dataset (as listed in Table ) was assessed by comparing the predicted PDFs to those obtained from DNS using the Jensen-Shannon divergence (JSD) . The JSD measures the similarity between two distributions $P_1$ and $P_2$ and is calculated as 

 (P_1||P_2) = 2_n=1^N (P_1(n) P_2(n) + P_2(n) P_1(n) ),
 

where $N$ denotes the total discretised points in the random variable space. The JSD value is bounded between $0$ and $(2)$, with smaller values indicating higher similarity between the two distributions. The PDFs from the model and DNS were taken as $P_1$ and $P_2$, respectively, and the JSD values for the marginal PDFs of the progress variable and the mixture fraction were calculated and plotted in Fig. .

Both the JPResUnet and ANN models exhibited high accuracy compared to the $$-PDF model, as their JSD plots for $(c_T)$ and $(Z)$ are clustered closer to zero. The mean JSD values for these models were approximately one-third and one-half of the corresponding values for the $$-PDF model, respectively. This finding reaffirms the superiority of the ANN model for in-sample predictions. The JPResUnet's similar performance to the ANN confirms its accuracy, though further improvements in in-sample prediction are beyond the scope of this study.

Testing with different filter widths and kernels

Due to constraints in computational and experimental resources, the availability of high-fidelity data for turbulent flames is currently limited, which makes it challenging to comprehensively cover practical scenarios, especially complex geometries. This limitation necessitates development of models that can be applied to scenarios significantly different from the training dataset. To validate this capability, the JPResUnet model was evaluated using data sampled from realisations of AZ1 at temporal steps beyond the range used for training. Additionally, since most LES utilise an implicit filter, where the filter type and size are unknown, the model was tested on data derived using various filter kernels and sizes to ensure its practical applicability.

The performance of the models was evaluated using data extracted with box and Gaussian filter kernels of widths $^+=1$, $1.5$, and $2$. Larger filter widths were not considered due to the size of DNS domain, as $^+=3$ approaches half the side length of the domain, resulting in an insufficient number of samples extracted from selected snapshots. Moreover, large filters fail to encompass a sufficient range of the turbulent kinetic energy, rendering the validated models impractical for a posteriori simulations and testing, as discussed in . The predicted joint and marginal PDFs for a local sub-grid space with the box and Gaussian kernels at the three filter sizes are presented in Fig. and , respectively. 

 

 

The predicted, both joint and marginal, PDFs are observed to be insensitive to the choice of the filter kernel, specifically for $^+=1$. At this width, there is minimal variation in filtered quantities, as shown in Fig. a and a. Consequently, the models, including the ANN and $$-PDF approach, generate consistent predictions despite the subtle input variations. The JPResUnet's predictions also remain constant since the inputs from the $$-distribution under both box and Gaussian filters are the same. Therefore, the discussion on local sub-grid PDF predictions focuses on the results obtained using the box filter only (Fig. ).

The JPResUnet demonstrates excellent performance, accurately reproducing the shape and peak of joint PDF contours across all filter widths, with close agreement with DNS results. This accuracy is particularly evident in $(c_T)$ at larger filter widths (as shown in Fig. d and f). In contrast, the $$-PDF approach fails to provide satisfactory predictions except for the marginal distribution of the mixture fraction. This analytical model generates statistical distributions, as the Gaussian-like shape observed in the $(c_T)$ plots, while missing the instantaneous features. This deficiency compromises the accuracy of the PDF-based approach in modelling instantaneous reaction rates, as will be further demonstrated later in this section.

The ANN model performs comparably to JPResUnet but shows noticeable under-predictions in marginal PDFs as filter width increases (as seen in Fig. f). Additionally, the joint PDF contours predicted by ANN exhibit wrinkled shapes, attributed to the unsteadiness of the instantaneous sub-grid PDFs (FDFs) used during training. JPResUnet avoids these issues by leveraging the statistical structure of $$-PDF while preserving sub-grid complexity, resulting in smooth and consistent predictions across filter sizes. This robustness underscores JPResUnetâ€™s high generalisation capability.

Figure presents the PDF of the JSD values for model predictions at varying filter widths and kernels (solid and dashed lines correspond to the box and Gaussian filters, respectively). The mean JSD values for each model's predictions with the box (and also Gaussian) filter are listed. JPResUnet demonstrates consistent high accuracy across all filter widths and types, with over $80\

Using the predicted joint PDF, the filtered reaction rate source term $_c_T$ is calculated similarly to Eq. (), where the flamelet reaction rate and density in the integrand are replaced with the doubly conditional averaging counterparts $<_c_T/|c_T,Z>$ over the DNS data (60 snapshots in total), as verified in . The reaction rate of $c_T$ is calculated as $_c_T=/[c_p(T_b-T_u)]$, where $$ and $c_p$ are the volumetric heat release rate and mixture specific heat capacity respectively. The comparison between the filtered reaction rates calculated by using the joint PDF from models $_c_T^$ and from DNS $_c_T^$ with different filter widths is illustrated in the scatter plot shown in Fig. . Due to the similarity of the joint PDFs predicted using the box and Gaussian filters, the modelled filtered reaction rates are very similar, so only the results for the box filter are shown here (the results for the Gaussian filter are in the supplementary material).

Among all the models, JPResUnet demonstrates the best performance across all filter sizes, accurately modelling the filtered reaction rate closely clustered around the diagonal without noticeable over- or under-prediction. Similarly, ANN provides comparable predictions with substantial overlap with JPResUnet. However, as filter size increases, ANN's predictions become more scattered, reflecting a decline in predictive performance discussed previously. The analytical $$-PDF approach produces reasonable estimates but consistently over-predicts the reaction rate $_c_T^$ across all filter widths, aligning with prior observations .

The accuracy of filtered reaction rate modelling is assessed using the root-mean-square of a normalised error (RMSE), defined as

 ^ = N _i=1^N(_c_T,i^-_c_T,i^_c_T,i^ )^2,
 

where the index $i$ denotes each sample in the test dataset with the size $N$. The RMSE values for each model with the box (and Gaussian) filter at all filter widths are listed in Table . The RMSE values for JPResUnet are the lowest for all filter widths and remain below 0.1 for both box and Gaussian kernels. By contrast, the RMSE value for the ANN increases significantly with the filter width, reaching around 1.5 times the value of JPResUnet's predictions. Although the $$-PDF approach shows improved performance at higher filter widths, its RMSE remains the highest, due to the over-prediction observed in Fig. c. 

Extrapolating to a higher dilution level

The extrapolation capability of the JPResUnet model has been rigorously assessed and shown to be robust across different filter widths, demonstrating improved accuracy compared to both the state-of-the-art ML model and the widely used analytical model. To further evaluate this capability, JPResUnet was tested on a distinct MILD combustion case, BZ1, which exhibits different thermo-chemical and -physical characteristics from the training case AZ1 (detailed in Section ). The model evaluations were conducted using data extracted with two filter widths, $^+=1$ and $1.5$.

The local sub-grid distributions within the reaction zone obtained using the box kernel are depicted in Fig. . The results for the Gaussian kernel are similar, which are included in . Unlike the AZ1 case, the DNS joint PDFs for BZ1 display a less pronounced bimodal distribution and a more dispersed shape, indicating a more distributed reaction zone. JPResUnet accurately captures these characteristics across all filter widths, with its predictions aligning closely with DNS. In contrast, the ANN model predicts the joint PDF contour with a discontinuity at $^+=1$, as evidenced by fluctuations in the marginal PDF for the mixture fraction (Fig. b), and significantly underpredicts the marginal PDF for the progress variable. At the larger filter width, ANN fails to produce a reasonable PDF, with the output resembling a highly concentrated delta-distribution, as illustrated in Figs. c and d. These results underscore the excellent generality of JPResUnet. By leveraging the PDF-translation mechanism introduced in Section , it is well-suited for cases with a reasonable statistical distribution of the sub-grid space. Conversely, ANN's performance is limited by its training dataset, resulting in poor predictions when the test case deviates significantly from the training data.

The overall accuracy of the models over the test dataset is compared using JSD of the PDF predictions in Fig. . Similar to the previous observation (Fig. ), JPResUnet achieves the highest predictive accuracy, with over $80\

The filtered reaction rate modelled by different approaches with the box filter is compared to DNS results in Fig. , with results for the Gaussian filter provided in . Among all models, JPResUnet delivers the most accurate predictions, which are tightly clustered around the diagonal, despite slight underprediction at $^+=1.5$. In contrast, the ANN model exhibits significant under-predictions due to inaccurate PDF predictions, while the $$-PDF approach shows over-prediction for the region of intense reaction. The RMSE values presented in Table confirm the very good performance of JPResUnet, remaining the lowest RMSE (around 0.1). By comparison, the ANN modelâ€™s inferior performance is quantitatively evidenced by high RMSE values, exceeding 0.2 at $^+=1.5$.

a posteriori assessment
 

The preceding section illustrates the performance of the JPResUnet model in predicting sub-grid PDFs for various MILD combustion scenarios within an a priori assessment framework. This performance is benchmarked against the ANN and $$-distribution approach on out-of-sample filter widths and kernels. Notably, JPResUnet maintains consistently high predictive accuracy across these conditions. Consequently, the model is evaluated in an a posteriori LES to substantiate its robustness and potential in practice.

LES setup
 
The experimental setup of the multi-regime burner (MRB) is shown schematically in Fig. . This involves three streams with different flow rates and equivalence ratios, resulting in inhomogeneous mixing of reactants downstream of the central jet. The bluff body positioned between slots 1 and 2 generates a recirculation zone composed of burnt products, stabilising the inner and outer flames. A high-velocity, fuel-rich premixed methane--air mixture is issued through the central jet, while pure air is supplied through slot 1. A range of equivalence ratios of the central premixed jet and bulk-mean air velocity for slot 1 is considered in the experimental study of . One of those cases, MRB26b, is considered for the a posteriori testing of the ML models presented in the previous section. This specific case is considered because it showed clear multi-regime combustion including local mixtures having mixture fraction values beyond the flammability limits . The equivalence ratio of the central methane--air jet is 2.6, with a velocity of m/s. The bulk-mean air velocity is m/s for slot 1. The lean premixed methane--air mixture with an equivalence ratio of 0.8 flows through slot 2 at a velocity of m/s. The flame is shielded from the external disturbances by using a low-velocity air co-flow around the burner. The temperatures of the mixtures introduced through the jet, slot 1, slot 2, and the co-flow are , , , and K respectively. Further details on the burner configuration and measurement techniques are discussed by Butz et al. .

The numerical setup follows the previous study . The computational domain is cylindrical, with a radius of mm and a length of mm from the exit of the central jet nozzle, which corresponds to approximately five times the flame length. This domain is discretised using about 3.5M hexahedral numerical cells. The finest resolution is applied within the central jet region, which has the highest velocity. The mesh size ranges from 0.1 to mm in the inner flame region. The outer flame region has cell sizes ranging from 0.4 to mm. The velocity boundary conditions at the inlets utilise an inflow turbulence generator based on the synthetic eddy method . A three-dimensional steady RANS with the Reynolds stress equation model is conducted to obtain the mean profiles of velocity, the Reynolds stress tensor, and the streamwise integral length scale required for the LEMOS inflow generator . Wave transmissive boundary conditions are imposed on the outflow boundaries to prevent acoustic wave reflection. All burner geometry walls are set to be no-slip and adiabatic.

In the a priori assessment, JPResUnet has demonstrated its effectiveness in capturing the instantaneous features of sub-grid distributions, indicating the potential for real-time inference during the simulation. However, the primary challenge associated with on-the-fly deployment is the computational cost. The numerous nonlinear operations inherent in ML models significantly increase the computational burden compared to widely used tabulation methods, which rely on linear interpolation within a relatively low-dimensional look-up table (LUT). The computational costs increase with model complexity. Consequently, a tabulation approach was employed as a practical compromise with tables generated using ML model, JPResUnet, tested in the previous section. The filtered reaction rate source terms $_$ and $^*$ modelled by using JPResUnet were stored in a new LUT, which were retrieved during the simulation. Future research will explore more promising alternatives, such as integrating JPResUnet in LES using GPU acceleration for on-the-fly inference.

The simulations are performed using OpenFOAM v7 with a modified PIMPLE algorithm (rhoPimpleFoam solver). Second-order central difference schemes are used for velocity, and an implicit Euler scheme is employed for time marching, with a small variable time step on the order of $(10^-7)$ to ensure the CFL number remains below 0.4 across the entire domain. Time-averaged statistics are obtained over a period of 25 flow-through times, which is necessary to achieve convergence due to the presence of low-velocity, large-scale structures within the recirculation zone. The flow-through time is based on the size of the recirculation zone, the distance upstream to slot 2, and the velocity of slot 2; one flow-through time is approximately ms, and five flow-through times are required for the flames to stabilise after ignition. The simulation is run on ARCHER2, a UK high-performance computing facility, using 1920 cores for h of wall clock time.

Results
 
The results of a posteriori assessment of the JPResUnet are compared with the experiment as well as the prior LES study employing a $$-PDF-based LUT (referred to as $_$). It is worth noting that the case $_$ uses the PDF with the resolution of $400500$ in the $c Z$ space for the reaction rate modelling in Eq. (), significantly finer than the resolution of $80100$ for JPResUnet. To investigate the effect of the resolution, a higher-resolution version with $384384$ is also used ($400500$ is not used because of excessive demand for computer memory). Hereinafter, results from this higher-resolution JPResUnet are denoted with the subscript `hr', while those from the lower-resolution JPResUnet tested in Section are denoted with the subscript `lr'. 

Figure presents the radial profiles of time-averaged and root-mean-squared (RMS) axial velocity, mixture fraction, and temperature at various streamwise locations, with all results averaged in the azimuthal direction. The velocity field is not affected by PDF models, with mean and RMS axial velocities (Fig. a) showing indistinguishable profiles across all approaches and aligning well with experimental data. The mixture fraction profiles (Fig. b) exhibit similar trends, with all approaches producing comparable results that closely match experimental data in the inner reaction region and over- and under-predict the mean and RMS values, respectively, for the outer shear layer of slot 2. Notably, the sensitivity to PDF resolution of JPResUnet is detected, with the lower-resolution JPResUnet (represented by blue lines) showing slightly more deviations than other simulations.

Regarding the temperature field (Fig. c), all simulations exhibit similar radial profiles that align well with experimental data in the near-field region (below mm). Further downstream (60 to mm), simulations show a good agreement with the measurement around the jet region with a slight over-prediction of the mean value. For the outer flame ($r mm$), the mean temperature is over-predicted, indicating insufficient air entrainment , and the peak of the RMS value is shifted towards a higher radial position. The high-resolution JPResUnet (represented by red lines) improves agreement with experimental data, particularly at mm, where it reduces both the mean temperature over-prediction and RMS peak shift. Conversely, the low-resolution model amplifies these deviations, underscoring the critical role of PDF resolution in achieving accurate predictions. 

Overall, with proper resolution in the PDF space, JPResUnet demonstrates very good accuracy in a posteriori assessments, especially in regions where the $$-PDF model struggles. It is stressed here again that the current deployment of the JPResUnet is a compromise due to the limited computational resources. As a model trained by an instantaneous dataset, on-the-fly inference should be conducted in future to further validate and strengthen the above findings.

Conclusion
 
This study developed a novel PDF-translation model, JPResUnet, inspired by image-to-image translation techniques and utilising a residual U-net architecture. The model predicts the sub-grid joint probability density function (PDF) of the progress variable and mixture fraction in partially premixed flames, leveraging the analytical $$-PDF as input. This approach ensures consistent translation within the PDF space during training and testing, enhancing the model's generalisability across diverse applications. Training was conducted using direct numerical simulation (DNS) data from the methane--air Moderate or Intense Low-oxygen Dilution (MILD) combustion, with a box filter at unit-normalised width. 

The performance of JPResUnet was first validated through an a priori assessment against a well-studied Artificial Neural Network (ANN) and the $$-PDF approach. On in-sample data, JPResUnet achieved predictive accuracy comparable to the ANN while outperforming the $$-distribution, as demonstrated by the contours of local sub-grid distributions and Jensen-Shannon Divergence (JSD) values.

For out-of-sample data with varying filter kernels and widths, JPResUnet provided consistently accurate predictions of local sub-grid PDFs and produced smoother contours compared to ANN, reducing sensitivity to unsteadiness in the training data. It also demonstrated good performance in modelling the filtered reaction rate source term, achieving the lowest root-mean-square error (RMSE) across all filter widths, while the ANN performance declined with increasing filter widths.

JPResUnet's generalisability was further assessed in the case of MILD combustion with a higher dilution level than the training case at two filter widths. JPResUnet's predictions closely matched the DNS results, while the ANN's predictions deteriorated significantly to entire failure at $^+=1.5$. The JSD values for JPResUnet remained the lowest, while those for ANN increased to approximately twice that of JPResUnet at the large filter width. JPResUnet also aligned closely with DNS in modelling the filtered reaction rate source term, with the lowest RMSEs, in contrast to ANN's substantial under-prediction, particularly at $^+=1.5$.

An a posteriori assessment of JPResUnet was conducted through a large eddy simulation (LES) of the multi-regime burner (MRB). To address the computational cost of on-the-fly inference, JPResUnet was implemented via a look-up table (LUT), and compared against experimental data and a conventional $$-PDF-based LUT. An additional JPResUnet with a higher PDF resolution ($384 384$ in $c Z$) was tested to assess the influence of resolution. While the velocity and mixture fraction fields showed negligible differences, the high-resolution JPResUnet reduced deviations in the temperature field, particularly in the outer reaction region at downstream locations. In contrast, increased deviations were observed for low-resolution JPResUnet, implying the performance is sensitive to the PDF resolution.

In conclusion, JPResUnet demonstrates robust performance across various combustion scenarios, surpassing traditional methods in accurately capturing complex features and exhibiting better generality compared to the ANN. Its ability to reduce deviations in both a priori and a posteriori assessments underscores the potential for LES applications. Future research will focus on optimising computational efficiency to enhance the modelâ€™s applicability in practice.

Detailed JPResUnet structure

Results for the Gaussian filter